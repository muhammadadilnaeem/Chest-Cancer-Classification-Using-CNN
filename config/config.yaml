

# Define the root directory for storing artifacts
artifacts_root: artifacts

# Configuration for data ingestion
data_ingestion:
  # Directory where data ingestion artifacts will be stored
  root_dir: artifacts/data_ingestion
  # URL to the source file containing the dataset (in this case, a Google Drive link)
  source_URL: https://drive.google.com/file/d/1z0mreUtRmR-P-magILsDR3T7M6IkGXtY/view?usp=sharing # for binary classification
  #source_URL: https://drive.google.com/file/d/1V18OgY4vvoUY1Wu0YZZzcD8U-vxKLFu9/view?usp=sharing   # for multi class classification
  # Path where the downloaded data file will be saved locally
  local_data_file: artifacts/data_ingestion/data.zip
  # Directory where the unzipped data will be stored
  unzip_dir: artifacts/data_ingestion

# Configuration for preparing the base model
prepare_base_model:
  # Directory for storing artifacts related to the base model preparation
  root_dir: artifacts/prepare_base_model
  # Path to the original base model file
  base_model_path: artifacts/prepare_base_model/base_model.h5
  # Path to the updated base model file after modifications
  updated_base_model_path: artifacts/prepare_base_model/base_model_updated.h5

# Configuration for training
training:
  # Directory for storing training artifacts
  root_dir: artifacts/training
  # Path where the trained model will be saved
  trained_model_path: artifacts/training/model.h5